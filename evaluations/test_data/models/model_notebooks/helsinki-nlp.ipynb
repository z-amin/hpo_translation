{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2e9d5df770a7d1",
   "metadata": {
    "id": "6c2e9d5df770a7d1"
   },
   "source": [
    "# Running pre-trained models on biomedical texts to evaluate them\n",
    "## Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/UPM/Thesis/Experiments/Test"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LX88ITVZPuZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716203196584,
     "user_tz": -120,
     "elapsed": 32136,
     "user": {
      "displayName": "Zaki Amin",
      "userId": "04947632139018387421"
     }
    },
    "outputId": "00d19b30-5209-41d2-d522-1ec5c40c8a51"
   },
   "id": "0LX88ITVZPuZ",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92381a6bc32b6463",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92381a6bc32b6463",
    "outputId": "f5110be5-3ff5-4670-c3f1-39243bec17dc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716203260718,
     "user_tz": -120,
     "elapsed": 64138,
     "user": {
      "displayName": "Zaki Amin",
      "userId": "04947632139018387421"
     }
    }
   },
   "source": [
    "!pip install transformers tqdm sentencepiece sacremoses accelerate ipywidgets protobuf\n",
    "# pytorch"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c37f8cd1cb3e5a47",
   "metadata": {
    "id": "c37f8cd1cb3e5a47",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716203260719,
     "user_tz": -120,
     "elapsed": 11,
     "user": {
      "displayName": "Zaki Amin",
      "userId": "04947632139018387421"
     }
    }
   },
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "\n",
    "class TranslationModel:\n",
    "    def __init__(self, checkpoint_name: str):\n",
    "        self.checkpoint_name = checkpoint_name\n",
    "\n",
    "    @abstractmethod\n",
    "    def translate(self, source: str) -> str:\n",
    "        \"\"\"Translates a source text with the model\n",
    "        :param source: the text to translate\n",
    "        :return: str - the translation\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"helsinki-nlp\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f169902b3db78872",
   "metadata": {
    "id": "f169902b3db78872"
   },
   "source": [
    "### Helsinki-NLP/opus-mt-en-es"
   ]
  },
  {
   "cell_type": "code",
   "id": "3ec64c835e29d26f",
   "metadata": {
    "id": "3ec64c835e29d26f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716203266952,
     "user_tz": -120,
     "elapsed": 6241,
     "user": {
      "displayName": "Zaki Amin",
      "userId": "04947632139018387421"
     }
    }
   },
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "\n",
    "class HelsinkiNLPModel(TranslationModel):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Helsinki-NLP/opus-mt-en-es\")\n",
    "        self.model = MarianMTModel.from_pretrained(self.checkpoint_name)\n",
    "        self.tokenizer = MarianTokenizer.from_pretrained(self.checkpoint_name)\n",
    "\n",
    "    def translate(self, source: str) -> str:\n",
    "        input_ids = self.tokenizer.encode(source, return_tensors=\"pt\")\n",
    "        translated_tokens = self.model.generate(input_ids, num_beams=4, early_stopping=True)\n",
    "        translated_text = self.tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "        return translated_text"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1c17fb211e964c4",
   "metadata": {
    "id": "1c17fb211e964c4"
   },
   "source": [
    "## Loading and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b2b36bc1be316f1",
   "metadata": {
    "id": "8b2b36bc1be316f1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716203266953,
     "user_tz": -120,
     "elapsed": 7,
     "user": {
      "displayName": "Zaki Amin",
      "userId": "04947632139018387421"
     }
    }
   },
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_sentences(test_dataset: str) -> pd.DataFrame:\n",
    "    \"\"\"Loads a test dataset in .jsonl format into a dataframe and randomly selects n rows\n",
    "    :param test_dataset: filename of the test dataset\n",
    "    :return pd.Dataframe: the parallel corpus as a dataframe\"\"\"\n",
    "    data = []\n",
    "    with open(test_dataset, \"r\") as f:\n",
    "        for line in f:\n",
    "            loaded = json.loads(line)\n",
    "            english, spanish = loaded['en'].strip('\"'), loaded['es'].strip('\"')\n",
    "            data.append({\"en\": english, \"es\": spanish})\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def run_model(model: TranslationModel, test_sentences: pd.DataFrame):\n",
    "    \"\"\"Runs a model on the test sentences. Creates a dataframe for the results with two columns: 'Reference' and 'Actual'\n",
    "    :param model: the MT model to evaluate\n",
    "    :param test_sentences: a dataframe for a parallel corpus\"\"\"\n",
    "    df = pd.DataFrame(columns=['reference', 'actual'])\n",
    "    for _, row in tqdm(test_sentences.iterrows(), total=test_sentences.shape[0]):\n",
    "        english, spanish = row['en'], row['es']\n",
    "        translation = model.translate(english)\n",
    "        df.loc[len(df.index)] = [spanish, translation]\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_on_all_test_datasets(translation_model: TranslationModel, dataset_names: list[str],\n",
    "                             corpus_directory: str):\n",
    "    for test_dataset in dataset_names:\n",
    "        test_path = corpus_directory + test_dataset\n",
    "        print(f\"Test dataset: {test_dataset}\")\n",
    "        test_sentences = load_sentences(test_path)\n",
    "        results = run_model(translation_model, test_sentences)\n",
    "        out_file = test_dataset.replace(\".jsonl\", \".csv\")\n",
    "        results.to_csv(f\"translations/{translation_model}/{out_file}\", index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cef891a86bb7091d",
   "metadata": {
    "id": "cef891a86bb7091d"
   },
   "source": [
    "## Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "id": "92159dcf4eaca7d8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "id": "92159dcf4eaca7d8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716203266953,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "Zaki Amin",
      "userId": "04947632139018387421"
     }
    }
   },
   "source": [
    "test_directory = \"data/\"\n",
    "filenames = [\"pubmed-te.jsonl\", \"clinspen-te.jsonl\", \"hpo.jsonl\", \"khresmoi-te.jsonl\", \"orphanet-definitions-te.jsonl\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "72ab51328f9f73e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "id": "72ab51328f9f73e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1716203615792,
     "user_tz": -120,
     "elapsed": 301581,
     "user": {
      "displayName": "Zaki Amin",
      "userId": "04947632139018387421"
     }
    },
    "outputId": "98f0776d-c633-4068-8857-8659eda76a3f"
   },
   "source": "run_on_all_test_datasets(HelsinkiNLPModel(), filenames, test_directory)",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "colab": {
   "provenance": [],
   "gpuType": "L4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
