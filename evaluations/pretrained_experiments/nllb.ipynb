{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c2e9d5df770a7d1",
   "metadata": {
    "id": "6c2e9d5df770a7d1"
   },
   "source": [
    "# Running pre-trained models on biomedical texts to evaluate them\n",
    "## Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Year abroad/Thesis/Experiments"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LX88ITVZPuZ",
    "outputId": "a1f021f5-291e-443d-9431-ee41c4a98392"
   },
   "id": "0LX88ITVZPuZ",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "92381a6bc32b6463",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T14:24:29.290010Z",
     "start_time": "2024-04-29T14:24:29.287184Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "92381a6bc32b6463",
    "outputId": "1464dd5d-b1c0-468e-9032-ef26ab331abb"
   },
   "source": [
    "!pip install transformers tqdm sentencepiece sacremoses accelerate ipywidgets protobuf\n",
    "# pytorch"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c37f8cd1cb3e5a47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T14:24:29.300272Z",
     "start_time": "2024-04-29T14:24:29.296582Z"
    },
    "id": "c37f8cd1cb3e5a47"
   },
   "source": [
    "from abc import abstractmethod\n",
    "\n",
    "\n",
    "class TranslationModel:\n",
    "    def __init__(self, checkpoint_name: str):\n",
    "        self.checkpoint_name = checkpoint_name\n",
    "\n",
    "    @abstractmethod\n",
    "    def translate(self, source: str) -> str:\n",
    "        \"\"\"Translates a source text with the model\n",
    "        :param source: the text to translate\n",
    "        :return: str - the translation\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.checkpoint_name"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f169902b3db78872",
   "metadata": {
    "id": "f169902b3db78872"
   },
   "source": "### facebook/nllb-200-distilled-600M"
  },
  {
   "cell_type": "code",
   "id": "3ec64c835e29d26f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T14:24:29.314803Z",
     "start_time": "2024-04-29T14:24:29.310562Z"
    },
    "id": "3ec64c835e29d26f"
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "class NLLBModel(TranslationModel):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"facebook/nllb-200-distilled-600M\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.checkpoint_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(self.checkpoint_name)\n",
    "\n",
    "    def translate(self, source: str) -> str:\n",
    "        inputs = self.tokenizer(source, return_tensors=\"pt\")\n",
    "        translated_tokens = self.model.generate(\n",
    "            **inputs, forced_bos_token_id=self.tokenizer.lang_code_to_id[\"spa_Latn\"], max_length=1000\n",
    "        )\n",
    "        translated_text = self.tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "        return translated_text"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1c17fb211e964c4",
   "metadata": {
    "id": "1c17fb211e964c4"
   },
   "source": [
    "## Loading and evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b2b36bc1be316f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T14:24:29.339422Z",
     "start_time": "2024-04-29T14:24:29.331Z"
    },
    "id": "8b2b36bc1be316f1"
   },
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def load_sentences(test_dataset: str, num_rows=500, seed=42) -> pd.DataFrame:\n",
    "    \"\"\"Loads a test dataset in .jsonl format into a dataframe and randomly selects n rows\n",
    "    :param test_dataset: filename of the test dataset\n",
    "    :param num_rows: number of rows to select\n",
    "    :param seed: random seed for reproducibility\n",
    "    :return pd.Dataframe: the parallel corpus as a dataframe\"\"\"\n",
    "    data = []\n",
    "    with open(test_dataset, \"r\") as f:\n",
    "        for line in f:\n",
    "            loaded = json.loads(line)\n",
    "            english, spanish = loaded['en'].strip('\"'), loaded['es'].strip('\"')\n",
    "            data.append({\"en\": english, \"es\": spanish})\n",
    "    df = pd.DataFrame(data)\n",
    "    return df.sample(n=num_rows, random_state=seed)\n",
    "\n",
    "\n",
    "def run_models(model: TranslationModel, test_sentences: pd.DataFrame):\n",
    "    \"\"\"Runs a model on the test sentences. Creates a dataframe for the results with two columns: 'Reference' and 'Actual'\n",
    "    :param model: the MT model to evaluate\n",
    "    :param test_sentences: a dataframe for a parallel corpus\"\"\"\n",
    "    df = pd.DataFrame(columns=['reference', 'actual'])\n",
    "\n",
    "    for _, row in tqdm(test_sentences.iterrows()):\n",
    "        english, spanish = row['en'], row['es']\n",
    "        translation = model.translate(english)\n",
    "        df.loc[len(df.index)] = [spanish, translation]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def evaluate_on_all_test_data(translation_model: TranslationModel, dataset_names: list[str],\n",
    "                              corpus_directory: str):\n",
    "    for test_dataset in dataset_names:\n",
    "        test_path = corpus_directory + test_dataset\n",
    "        print(f\"Test dataset: {test_dataset}\")\n",
    "        test_sentences = load_sentences(test_path, num_rows=500)\n",
    "        results = run_models(translation_model, test_sentences)\n",
    "        results.to_csv(\"nllb/\" + test_dataset.replace(\".jsonl\", \".csv\"), index=False)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cef891a86bb7091d",
   "metadata": {
    "id": "cef891a86bb7091d"
   },
   "source": [
    "## Evaluating the models"
   ]
  },
  {
   "cell_type": "code",
   "id": "92159dcf4eaca7d8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-29T14:24:29.340696Z"
    },
    "id": "92159dcf4eaca7d8"
   },
   "source": [
    "test_directory = \"train/\"\n",
    "filenames = [\"abstracts.jsonl\", \"khresmoi.jsonl\", \"medline.jsonl\", \"scielo.jsonl\", \"snomed.jsonl\"]"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "72ab51328f9f73e",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "72ab51328f9f73e",
    "outputId": "a535f659-14fd-421a-9f95-662487f8aa16"
   },
   "source": "evaluate_on_all_test_data(NLLBModel(), filenames, test_directory)",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
